{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.feature_selection import RFE\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.pipeline import Pipeline\n",
    "%matplotlib inline\n",
    "from imblearn.combine import SMOTETomek\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Training Data\n",
    "trainSet  = pd.read_csv('train.csv')\n",
    "trainingEncoded = pd.get_dummies(trainSet)\n",
    "x = trainingEncoded.drop(['hand'], axis=1)\n",
    "y = trainingEncoded['hand']\n",
    "xTrain, xVal, yTrain, yVal = train_test_split(x, \n",
    "                                              y,\n",
    "                                              test_size=.1,\n",
    "                                              random_state=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    11273\n",
      "1     9511\n",
      "2     1080\n",
      "3      458\n",
      "4       87\n",
      "5       48\n",
      "6       36\n",
      "7        6\n",
      "9        5\n",
      "8        5\n",
      "Name: hand, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Convert to panda data frame for printing contents\n",
    "pdTraining = pd.DataFrame(data=yTrain, columns=['hand'])\n",
    "print pdTraining.hand.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1220\n",
      "1    1088\n",
      "2     126\n",
      "3      55\n",
      "5       6\n",
      "4       6\n",
      "Name: hand, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Print out the testing set contents\n",
    "pdTest = pd.DataFrame(data=yVal, columns=['hand'])\n",
    "print pdTest.hand.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the classifier\n",
    "model = RandomForestClassifier(n_estimators=30, random_state=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    2170\n",
      "1     331\n",
      "Name: hand, dtype: int64\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.51      0.91      0.66      1220\n",
      "          1       0.56      0.17      0.26      1088\n",
      "          2       0.00      0.00      0.00       126\n",
      "          3       0.00      0.00      0.00        55\n",
      "          4       0.00      0.00      0.00         6\n",
      "          5       0.00      0.00      0.00         6\n",
      "\n",
      "avg / total       0.49      0.52      0.43      2501\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kristiansuhartono/python-env/lib/python2.7/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# Fit the model with training data and do benchmarking with different number of attributes\n",
    "rfe = RFE(model, 2)\n",
    "rfe = rfe.fit(xTrain, yTrain)\n",
    "# print rfe.support_\n",
    "# print rfe.ranking_\n",
    "rfePredicted = rfe.predict(xVal)\n",
    "\n",
    "pdRfePredicted = pd.DataFrame(data=rfePredicted, columns=['hand'])\n",
    "print pdRfePredicted.hand.value_counts()\n",
    "\n",
    "print metrics.classification_report(yVal, pdRfePredicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1628\n",
      "1     846\n",
      "2      22\n",
      "3       5\n",
      "Name: hand, dtype: int64\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.60      0.80      0.68      1220\n",
      "          1       0.56      0.44      0.49      1088\n",
      "          2       0.14      0.02      0.04       126\n",
      "          3       1.00      0.09      0.17        55\n",
      "          4       0.00      0.00      0.00         6\n",
      "          5       0.00      0.00      0.00         6\n",
      "\n",
      "avg / total       0.56      0.58      0.55      2501\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rfe = RFE(model, 3)\n",
    "rfe = rfe.fit(xTrain, yTrain)\n",
    "# print rfe.support_\n",
    "# print rfe.ranking_\n",
    "rfePredicted = rfe.predict(xVal)\n",
    "\n",
    "pdRfePredicted = pd.DataFrame(data=rfePredicted, columns=['hand'])\n",
    "print pdRfePredicted.hand.value_counts()\n",
    "\n",
    "print metrics.classification_report(yVal, pdRfePredicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1357\n",
      "1    1047\n",
      "2      64\n",
      "3      25\n",
      "4       5\n",
      "5       2\n",
      "6       1\n",
      "Name: hand, dtype: int64\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.69      0.77      0.73      1220\n",
      "          1       0.60      0.58      0.59      1088\n",
      "          2       0.27      0.13      0.18       126\n",
      "          3       0.44      0.20      0.28        55\n",
      "          4       0.00      0.00      0.00         6\n",
      "          5       0.00      0.00      0.00         6\n",
      "          6       0.00      0.00      0.00         0\n",
      "\n",
      "avg / total       0.62      0.64      0.63      2501\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kristiansuhartono/python-env/lib/python2.7/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "rfe = RFE(model, 4)\n",
    "rfe = rfe.fit(xTrain, yTrain)\n",
    "# print rfe.support_\n",
    "# print rfe.ranking_\n",
    "rfePredicted = rfe.predict(xVal)\n",
    "\n",
    "pdRfePredicted = pd.DataFrame(data=rfePredicted, columns=['hand'])\n",
    "print pdRfePredicted.hand.value_counts()\n",
    "\n",
    "print metrics.classification_report(yVal, pdRfePredicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1450\n",
      "1    1008\n",
      "2      33\n",
      "3       7\n",
      "4       3\n",
      "Name: hand, dtype: int64\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.70      0.83      0.76      1220\n",
      "          1       0.65      0.61      0.63      1088\n",
      "          2       0.45      0.12      0.19       126\n",
      "          3       0.71      0.09      0.16        55\n",
      "          4       0.00      0.00      0.00         6\n",
      "          5       0.00      0.00      0.00         6\n",
      "\n",
      "avg / total       0.66      0.68      0.66      2501\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rfe = RFE(model, 5)\n",
    "rfe = rfe.fit(xTrain, yTrain)\n",
    "# print rfe.support_\n",
    "# print rfe.ranking_\n",
    "rfePredicted = rfe.predict(xVal)\n",
    "\n",
    "pdRfePredicted = pd.DataFrame(data=rfePredicted, columns=['hand'])\n",
    "print pdRfePredicted.hand.value_counts()\n",
    "\n",
    "print metrics.classification_report(yVal, pdRfePredicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1441\n",
      "1    1038\n",
      "2      18\n",
      "3       3\n",
      "4       1\n",
      "Name: hand, dtype: int64\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.68      0.80      0.73      1220\n",
      "          1       0.62      0.59      0.60      1088\n",
      "          2       0.44      0.06      0.11       126\n",
      "          3       1.00      0.05      0.10        55\n",
      "          4       0.00      0.00      0.00         6\n",
      "          5       0.00      0.00      0.00         6\n",
      "\n",
      "avg / total       0.64      0.65      0.63      2501\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rfe = RFE(model, 6)\n",
    "rfe = rfe.fit(xTrain, yTrain)\n",
    "# print rfe.support_\n",
    "# print rfe.ranking_\n",
    "rfePredicted = rfe.predict(xVal)\n",
    "\n",
    "pdRfePredicted = pd.DataFrame(data=rfePredicted, columns=['hand'])\n",
    "print pdRfePredicted.hand.value_counts()\n",
    "\n",
    "print metrics.classification_report(yVal, pdRfePredicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1475\n",
      "1    1018\n",
      "2       6\n",
      "3       2\n",
      "Name: hand, dtype: int64\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.65      0.78      0.71      1220\n",
      "          1       0.59      0.55      0.57      1088\n",
      "          2       0.50      0.02      0.05       126\n",
      "          3       1.00      0.04      0.07        55\n",
      "          4       0.00      0.00      0.00         6\n",
      "          5       0.00      0.00      0.00         6\n",
      "\n",
      "avg / total       0.62      0.62      0.60      2501\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rfe = RFE(model, 7)\n",
    "rfe = rfe.fit(xTrain, yTrain)\n",
    "# print rfe.support_\n",
    "# print rfe.ranking_\n",
    "rfePredicted = rfe.predict(xVal)\n",
    "\n",
    "pdRfePredicted = pd.DataFrame(data=rfePredicted, columns=['hand'])\n",
    "print pdRfePredicted.hand.value_counts()\n",
    "\n",
    "print metrics.classification_report(yVal, pdRfePredicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1539\n",
      "1     958\n",
      "3       2\n",
      "2       2\n",
      "Name: hand, dtype: int64\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.60      0.75      0.67      1220\n",
      "          1       0.54      0.48      0.51      1088\n",
      "          2       0.50      0.01      0.02       126\n",
      "          3       0.50      0.02      0.04        55\n",
      "          4       0.00      0.00      0.00         6\n",
      "          5       0.00      0.00      0.00         6\n",
      "\n",
      "avg / total       0.56      0.57      0.55      2501\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rfe = RFE(model, 8)\n",
    "rfe = rfe.fit(xTrain, yTrain)\n",
    "# print rfe.support_\n",
    "# print rfe.ranking_\n",
    "rfePredicted = rfe.predict(xVal)\n",
    "\n",
    "pdRfePredicted = pd.DataFrame(data=rfePredicted, columns=['hand'])\n",
    "print pdRfePredicted.hand.value_counts()\n",
    "\n",
    "print metrics.classification_report(yVal, pdRfePredicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1534\n",
      "1     962\n",
      "2       4\n",
      "3       1\n",
      "Name: hand, dtype: int64\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.62      0.78      0.69      1220\n",
      "          1       0.57      0.50      0.53      1088\n",
      "          2       0.50      0.02      0.03       126\n",
      "          3       1.00      0.02      0.04        55\n",
      "          4       0.00      0.00      0.00         6\n",
      "          5       0.00      0.00      0.00         6\n",
      "\n",
      "avg / total       0.60      0.60      0.57      2501\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rfe = RFE(model, 9)\n",
    "rfe = rfe.fit(xTrain, yTrain)\n",
    "# print rfe.support_\n",
    "# print rfe.ranking_\n",
    "rfePredicted = rfe.predict(xVal)\n",
    "\n",
    "pdRfePredicted = pd.DataFrame(data=rfePredicted, columns=['hand'])\n",
    "print pdRfePredicted.hand.value_counts()\n",
    "\n",
    "print metrics.classification_report(yVal, pdRfePredicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1544\n",
      "1     951\n",
      "2       5\n",
      "3       1\n",
      "Name: hand, dtype: int64\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.60      0.75      0.67      1220\n",
      "          1       0.55      0.48      0.52      1088\n",
      "          2       0.60      0.02      0.05       126\n",
      "          3       1.00      0.02      0.04        55\n",
      "          4       0.00      0.00      0.00         6\n",
      "          5       0.00      0.00      0.00         6\n",
      "\n",
      "avg / total       0.58      0.58      0.55      2501\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rfe = RFE(model, 10)\n",
    "rfe = rfe.fit(xTrain, yTrain)\n",
    "# print rfe.support_\n",
    "# print rfe.ranking_\n",
    "rfePredicted = rfe.predict(xVal)\n",
    "\n",
    "pdRfePredicted = pd.DataFrame(data=rfePredicted, columns=['hand'])\n",
    "print pdRfePredicted.hand.value_counts()\n",
    "\n",
    "print metrics.classification_report(yVal, pdRfePredicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('feature_selection', RFE(estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_spl...n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False))])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new classifier, using pipeline\n",
    "# Using RFE for feature selection and final classification model using RF\n",
    "clf = Pipeline([\n",
    "    ('feature_selection', RFE(model, 6)),\n",
    "    ('classification', RandomForestClassifier(n_estimators=30))\n",
    "])\n",
    "clf.fit(xTrain, yTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1449\n",
      "1    1036\n",
      "2      14\n",
      "3       1\n",
      "4       1\n",
      "Name: hand, dtype: int64\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.80      0.73      1220\n",
      "          1       0.61      0.58      0.60      1088\n",
      "          2       0.36      0.04      0.07       126\n",
      "          3       1.00      0.02      0.04        55\n",
      "          4       0.00      0.00      0.00         6\n",
      "          5       0.00      0.00      0.00         6\n",
      "\n",
      "avg / total       0.63      0.65      0.62      2501\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predict the result\n",
    "pipePredicted = clf.predict(xVal)\n",
    "\n",
    "pdPipePredicted = pd.DataFrame(data=pipePredicted, columns=['hand'])\n",
    "print pdPipePredicted.hand.value_counts()\n",
    "\n",
    "# Print out the score report\n",
    "print metrics.classification_report(yVal, pdPipePredicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load up rebalanced dataset\n",
    "balancedSet  = pd.read_csv('balence.csv')\n",
    "encodedBalanced = pd.get_dummies(balancedSet)\n",
    "balancedX = encodedBalanced.drop(['hand'], axis=1)\n",
    "balancedY = encodedBalanced['hand']\n",
    "xBalTrain, xBalVal, yBalTrain, yBalVal = train_test_split(balancedX, \n",
    "                                              balancedY,\n",
    "                                              test_size=.1,\n",
    "                                              random_state=12)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5    11275\n",
      "3    11273\n",
      "8    11270\n",
      "1    11265\n",
      "9    11244\n",
      "0    11243\n",
      "2    11227\n",
      "6    11226\n",
      "7    11220\n",
      "4    11194\n",
      "Name: hand, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Print out contents of dataset\n",
    "pdBalanced = pd.DataFrame(data=yBalTrain, columns=['hand'])\n",
    "print pdBalanced.hand.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('feature_selection', RFE(estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_spl...n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False))])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the training data to the pipeline, replacing previous model\n",
    "clf.fit(xBalTrain, yBalTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6    1536\n",
      "7    1374\n",
      "0    1353\n",
      "8    1338\n",
      "9    1265\n",
      "4    1243\n",
      "5    1204\n",
      "3    1144\n",
      "2    1109\n",
      "1     927\n",
      "Name: hand, dtype: int64\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.41      0.44      0.43      1250\n",
      "          1       0.41      0.31      0.36      1228\n",
      "          2       0.69      0.60      0.64      1266\n",
      "          3       0.76      0.71      0.73      1220\n",
      "          4       0.52      0.50      0.51      1299\n",
      "          5       0.43      0.42      0.42      1218\n",
      "          6       0.80      0.97      0.87      1267\n",
      "          7       0.93      1.00      0.96      1273\n",
      "          8       0.49      0.53      0.51      1223\n",
      "          9       0.99      1.00      0.99      1249\n",
      "\n",
      "avg / total       0.64      0.65      0.64     12493\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predict the result of the test set\n",
    "balPredicted = clf.predict(xBalVal)\n",
    "\n",
    "pdBalPredicted = pd.DataFrame(data=balPredicted, columns=['hand'])\n",
    "print pdBalPredicted.hand.value_counts()\n",
    "\n",
    "print metrics.classification_report(yBalVal, pdBalPredicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 554  153   15   15    3  507    0    0    3    0]\n",
      " [ 236  384  257  154   13  160    4    0   17    3]\n",
      " [  24  172  760   87    4   18  178   15    4    4]\n",
      " [  10   81   32  865    3    5  130   87    1    6]\n",
      " [   0    0    0    0  646    0    0    0  652    1]\n",
      " [ 529  137   15    9    5  514    0    0    7    2]\n",
      " [   0    0   30   13    0    0 1223    1    0    0]\n",
      " [   0    0    0    1    0    0    1 1271    0    0]\n",
      " [   0    0    0    0  569    0    0    0  654    0]\n",
      " [   0    0    0    0    0    0    0    0    0 1249]]\n"
     ]
    }
   ],
   "source": [
    "# Printout the confusion matrix\n",
    "print confusion_matrix(yBalVal, pdBalPredicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trying out SMOTE and Tomek Chains for over and under sampling of data\n",
    "smt = SMOTETomek(random_state=42, smote=SMOTE(random_state=12, ratio='minority', k_neighbors=10))\n",
    "resX, resY = smt.fit_sample(xBalTrain, yBalTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9    11244\n",
      "8    11180\n",
      "5    10635\n",
      "4    10569\n",
      "7    10447\n",
      "6     9557\n",
      "0     9028\n",
      "3     8949\n",
      "2     8660\n",
      "1     8265\n",
      "Name: hand, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Print out the resulting training dataset values\n",
    "pdBalanced = pd.DataFrame(data=resY, columns=['hand'])\n",
    "print pdBalanced.hand.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('feature_selection', RFE(estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_spl...n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False))])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the SMOTETomek rebalanced data\n",
    "clf.fit(resX, resY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8    1615\n",
      "6    1526\n",
      "5    1426\n",
      "7    1326\n",
      "9    1254\n",
      "0    1215\n",
      "3    1206\n",
      "2    1111\n",
      "4     950\n",
      "1     864\n",
      "Name: hand, dtype: int64\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.42      0.40      0.41      1250\n",
      "          1       0.41      0.29      0.34      1228\n",
      "          2       0.72      0.63      0.67      1266\n",
      "          3       0.77      0.76      0.77      1220\n",
      "          4       0.54      0.39      0.46      1299\n",
      "          5       0.41      0.48      0.45      1218\n",
      "          6       0.83      1.00      0.91      1267\n",
      "          7       0.96      1.00      0.98      1273\n",
      "          8       0.50      0.66      0.57      1223\n",
      "          9       1.00      1.00      1.00      1249\n",
      "\n",
      "avg / total       0.66      0.66      0.66     12493\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predict results with new model\n",
    "balPredicted = clf.predict(xBalVal)\n",
    "\n",
    "pdBalPredicted = pd.DataFrame(data=balPredicted, columns=['hand'])\n",
    "print pdBalPredicted.hand.value_counts()\n",
    "\n",
    "print metrics.classification_report(yBalVal, pdBalPredicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here on is submission generation, only run if needed (don't run over this point, if on .py file delete this)\n",
    "\n",
    "testSet  = pd.read_csv('test.csv')\n",
    "testEncoded = pd.get_dummies(testSet)\n",
    "testX = testEncoded.drop(['id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultDataRF = clf.predict(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    578784\n",
      "1    405665\n",
      "2     11129\n",
      "3      3184\n",
      "4       792\n",
      "5       242\n",
      "6       123\n",
      "8        44\n",
      "9        32\n",
      "7         5\n",
      "Name: hand, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "pdResultDataRF = pd.DataFrame(data=resultDataRF, columns=['hand'])\n",
    "pdResultDataRF.index += 1\n",
    "print pdResultDataRF.hand.value_counts()\n",
    "pdResultDataRF.to_csv(\"submission.csv\", index_label='id', columns=['hand'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
